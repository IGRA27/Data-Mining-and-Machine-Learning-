{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# AUTOR: Isaac Reyes\n"
      ],
      "metadata": {
        "id": "TgylmS69QOYs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10 Convolutional Neural Networks\n",
        "### CNNs are a specialized type of artificial neural network designed for processing grid-like data, such as images. They are particularly well-suited for computer vision tasks due to their ability to automatically learn hierarchical representations from raw pixel values. CNNs have been highly successful in various applications, such as image classification, object detection, image segmentation, and more."
      ],
      "metadata": {
        "id": "vyBc0xxyQIEC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "QtL55Y8kP3ZH"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from keras import layers, models\n",
        "import tensorflow_datasets as tfds\n",
        "from keras.applications import VGG16\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import itertools"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Dataset Preparation:\n",
        "\n",
        "Download and preprocess the Caltech-256 dataset.\n",
        "\n",
        "You can use the tensorflow_datasets library to load the dataset conveniently.\n",
        "\n",
        "Normalize the pixel values of the images to the range [0, 1].\n",
        "\n",
        "Split the dataset into training and testing sets."
      ],
      "metadata": {
        "id": "2ElHzYy7QZn7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(train_dataset, test_dataset), dataset_info = tfds.load(\n",
        "    name='caltech101',\n",
        "    split=['train[:80%]', 'train[80%:]'],\n",
        "    with_info=True,\n",
        "    as_supervised=True,\n",
        "    data_dir='/content/data/',\n",
        "\n",
        ")\n",
        "num_classes = dataset_info.features['label'].num_classes\n",
        "\n",
        "def preprocess_image(image, label):\n",
        "    image = tf.image.resize(image, (224, 224))\n",
        "    image = tf.cast(image, tf.float32) / 255.0\n",
        "    return image, label\n",
        "\n",
        "train_dataset = train_dataset.map(preprocess_image).shuffle(1000).batch(32)\n",
        "test_dataset = test_dataset.map(preprocess_image).batch(32)"
      ],
      "metadata": {
        "id": "WpEOKHoFQbz0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Build the CNN Model:\n",
        "\n",
        "Define a CNN model with the following architecture:\n",
        "\n",
        "Convolutional Layer 1: 32 filters, kernel size (3x3), ReLU activation.\n",
        "\n",
        "Max Pooling Layer 1: Pooling size (2x2).\n",
        "\n",
        "Convolutional Layer 2: 64 filters, kernel size (3x3), ReLU activation.\n",
        "\n",
        "Max Pooling Layer 2: Pooling size (2x2).\n",
        "\n",
        "Flatten the feature maps.\n",
        "\n",
        "Fully Connected Layer 1: 128 units, ReLU activation.\n",
        "\n",
        "Output Layer: Number of units equal to the number of classes in the Caltech-101 dataset."
      ],
      "metadata": {
        "id": "Lh88apKdQoXQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(num_classes, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "RtBzXCdwQx1O"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Training the Model:\n",
        "\n",
        "Compile the model with an appropriate optimizer and loss function.\n",
        "\n",
        "Train the model using the training dataset and validate it using the testing dataset.\n",
        "\n",
        "Observe the training process, including the loss and accuracy metrics."
      ],
      "metadata": {
        "id": "l5HWurL9Qw-f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Usamos un modelo previo llamado VGG16\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "#Congelamos las capas de la base\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "#Modelo personalizado para la salida VGG16\n",
        "x = base_model.output\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(512, activation='relu')(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "predictions = layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "#Modelo para entrenar\n",
        "model = models.Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "#Compilo\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "# Entrenar el modelo\n",
        "history = model.fit(train_dataset, epochs=5, validation_data=test_dataset)\n",
        "\n",
        "\n",
        "# Evaluar el modelo\n",
        "loss, accuracy = model.evaluate(test_dataset)\n",
        "print(f\"Accuracy on the test set: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dS1f8GZeQ5XG",
        "outputId": "ec27320f-ba26-4064-a284-a023f584d2c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "21/77 [=======>......................] - ETA: 18:49 - loss: 5.6771 - accuracy: 0.0312"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Understanding Parameter Sharing and Local Receptive Fields:\n",
        "\n",
        "Analyze the number of learnable parameters in each layer of the CNN model.\n",
        "\n",
        "¿What is parameter sharing? ¿What's its role in reducing the model's complexity?"
      ],
      "metadata": {
        "id": "815ltVfaRAyP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_params = model.count_params()\n",
        "print(f\"Number of trainable parameters in the model: {num_params}\")"
      ],
      "metadata": {
        "id": "wh-BRLV0RDqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Evaluation and Interpretation:\n",
        "\n",
        "Evaluate the model's performance on the testing dataset and calculate the accuracy.\n",
        "\n",
        "Visualize some misclassified images and discuss the possible reasons for misclassifications."
      ],
      "metadata": {
        "id": "MAMT5Ai3RR6r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(test_dataset)\n",
        "print(f\"Accuracy on the test set: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "TStuJTvGRUUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "misclassified_images = []\n",
        "misclassified_labels = []\n",
        "for image, label in test_dataset:\n",
        "    predictions = model.predict(image)\n",
        "    predicted_label = np.argmax(predictions, axis=1)\n",
        "    misclassified_idx = np.where(predicted_label != label.numpy())[0]\n",
        "    for idx in misclassified_idx:\n",
        "        misclassified_images.append(image[idx])\n",
        "        misclassified_labels.append(predicted_label[idx])\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(len(misclassified_images)):\n",
        "    plt.subplot(5, 5, i+1)\n",
        "    plt.imshow(misclassified_images[i])\n",
        "    plt.title(f\"Predicted: {misclassified_labels[i]}\")\n",
        "    plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ImHWuVX_RXie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Pick a sample image and show the feature maps activated by the convolutional layers"
      ],
      "metadata": {
        "id": "qYFPUPBBRWFK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the number of activations to visualize\n",
        "num_activations = len(activations)\n",
        "\n",
        "# Set up the number of rows and columns for the grid\n",
        "cols = 4\n",
        "rows = int(num_activations / cols) + (num_activations % cols > 0)\n",
        "\n",
        "# Create a plot to visualize the activations\n",
        "plt.figure(figsize=(15, 5 * rows))\n",
        "for i, activation in enumerate(activations):\n",
        "    plt.subplot(rows, cols, i + 1)\n",
        "    try:\n",
        "        plt.imshow(activation[0, :, :, 0], cmap='viridis')\n",
        "    except:\n",
        "        pass\n",
        "    plt.title(f\"Activation {i + 1}\")\n",
        "    plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "w1AW55G7Rcv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_image, _ = next(itertools.islice(iter(test_dataset), 0, 1))"
      ],
      "metadata": {
        "id": "tgb39EY6ReiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s = sample_image[:1]"
      ],
      "metadata": {
        "id": "YoIOjLatRg3z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}