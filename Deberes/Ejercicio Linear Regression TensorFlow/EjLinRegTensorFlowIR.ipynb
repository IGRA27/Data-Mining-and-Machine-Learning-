{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Ejercicio DEBER: Linear Regression with TensorFlow***\n",
    "### ***AUTOR: Isaac Reyes***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***7 Linear Regression with TensorFlow using the California Housing Dataset***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The goal of this exercise is to implement a linear regression model using TensorFlow to predict house prices based on the California Housing Dataset. The dataset contains various features such as average income, housing average age, and more. Your task is to build a linear regression model and evaluate its performance.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Import the required libraries:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_california_housing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the California Housing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = fetch_california_housing()\n",
    "X = pd.DataFrame(data=raw['data'], columns=raw['feature_names'])\n",
    "y = pd.Series(raw['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
      "0      8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
      "1      8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
      "2      7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
      "3      5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
      "4      3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
      "...       ...       ...       ...        ...         ...       ...       ...   \n",
      "20635  1.5603      25.0  5.045455   1.133333       845.0  2.560606     39.48   \n",
      "20636  2.5568      18.0  6.114035   1.315789       356.0  3.122807     39.49   \n",
      "20637  1.7000      17.0  5.205543   1.120092      1007.0  2.325635     39.43   \n",
      "20638  1.8672      18.0  5.329513   1.171920       741.0  2.123209     39.43   \n",
      "20639  2.3886      16.0  5.254717   1.162264      1387.0  2.616981     39.37   \n",
      "\n",
      "       Longitude  \n",
      "0        -122.23  \n",
      "1        -122.22  \n",
      "2        -122.24  \n",
      "3        -122.25  \n",
      "4        -122.25  \n",
      "...          ...  \n",
      "20635    -121.09  \n",
      "20636    -121.21  \n",
      "20637    -121.22  \n",
      "20638    -121.32  \n",
      "20639    -121.24  \n",
      "\n",
      "[20640 rows x 8 columns] 0        4.526\n",
      "1        3.585\n",
      "2        3.521\n",
      "3        3.413\n",
      "4        3.422\n",
      "         ...  \n",
      "20635    0.781\n",
      "20636    0.771\n",
      "20637    0.923\n",
      "20638    0.847\n",
      "20639    0.894\n",
      "Length: 20640, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocess the data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-Normalize the features using the mean and standard deviation.\n",
    "\n",
    "-Split the dataset into training and testing sets (e.g., 80% for training, 20% for testing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mas librerias:\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normaliza las características utilizando la media y la desviación estándar\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Divide el dataset en conjuntos de entrenamiento y prueba (80% para entrenamiento, 20% para prueba)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define the TensorFlow graph:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-Create placeholders for the input features (X) and target variable (y).\n",
    "\n",
    "-Create variables for the model's weights (W) and bias (b).\n",
    "\n",
    "-Define the linear regression model using the equation: y_pred = X * W + b.\n",
    "\n",
    "-Define the loss function as the mean squared error between the predicted values and the true values.\n",
    "\n",
    "-Choose an optimizer (e.g., Gradient Descent) to minimize the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ERRO PARA TENSORFLOW 2\n",
    "# Crear un modelo Sequential\n",
    "#model = Sequential()\n",
    "#CORREGIR\n",
    "#VERSION DE TENSORFLOW 2, PLACEHOLDER NO SOPORTA 2\n",
    "\n",
    "#CORRECCION TENSORFLOW2\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(1, input_dim=X_train.shape[1]))\n",
    "\n",
    "# para tensorflow 1:Añadir una capa Dense con regularización L2\n",
    "# La entrada es el número de características en el conjunto de datos\n",
    "\n",
    "#TensorFlow2: Compila el modelo con el optimizador SGD y la función de pérdida MSE:\n",
    "model.compile(optimizer='sgd', loss='mean_squared_error')\n",
    "\n",
    "#Para el TF1: Compilar el modelo con el optimizador SGD y la función de pérdida MSE\n",
    "#W = tf.Variable(tf.random_normal_initializer([X_train.shape[1],1]))\n",
    "#b = tf.Variable(tf.random_normal_initializer(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAIN THE MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-Initialize TensorFlow session.\n",
    "\n",
    "-Initialize the model's variables.\n",
    "\n",
    "-Set the number of training epochs and the learning rate.\n",
    "\n",
    "-For each epoch, iterate through the training dataset and update the model's parameters using the optimizer.\n",
    "\n",
    "-Print the training loss at regular intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "516/516 [==============================] - 2s 2ms/step - loss: 7.1058\n",
      "Epoch 2/50\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 4.5175\n",
      "Epoch 3/50\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 2.8649\n",
      "Epoch 4/50\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 1.8904\n",
      "Epoch 5/50\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 1.3472\n",
      "Epoch 6/50\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 1.0586\n",
      "Epoch 7/50\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.9134\n",
      "Epoch 8/50\n",
      "516/516 [==============================] - 1s 1ms/step - loss: 0.8325\n",
      "Epoch 9/50\n",
      "516/516 [==============================] - 1s 1ms/step - loss: 0.7825\n",
      "Epoch 10/50\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.7478\n",
      "Epoch 11/50\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.7163\n",
      "Epoch 12/50\n",
      "516/516 [==============================] - 1s 1ms/step - loss: 0.6887\n",
      "Epoch 13/50\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.6632\n",
      "Epoch 14/50\n",
      "516/516 [==============================] - 1s 1ms/step - loss: 0.6413\n",
      "Epoch 15/50\n",
      "516/516 [==============================] - 1s 1ms/step - loss: 0.6206\n",
      "Epoch 16/50\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.6031\n",
      "Epoch 17/50\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.5880\n",
      "Epoch 18/50\n",
      "516/516 [==============================] - 1s 1ms/step - loss: 0.5741\n",
      "Epoch 19/50\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.5616\n",
      "Epoch 20/50\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.5512\n",
      "Epoch 21/50\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.5422\n",
      "Epoch 22/50\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.5352\n",
      "Epoch 23/50\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.5303\n",
      "Epoch 24/50\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.5260\n",
      "Epoch 25/50\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.5228\n",
      "Epoch 26/50\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.5209\n",
      "Epoch 27/50\n",
      "516/516 [==============================] - 1s 1ms/step - loss: 0.5195\n",
      "Epoch 28/50\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.5190\n",
      "Epoch 29/50\n",
      "516/516 [==============================] - 1s 1ms/step - loss: 0.5191\n",
      "Epoch 30/50\n",
      "516/516 [==============================] - 1s 1ms/step - loss: 0.5189\n",
      "Epoch 31/50\n",
      "516/516 [==============================] - 1s 1ms/step - loss: 0.5190\n",
      "Epoch 32/50\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.5191\n",
      "Epoch 33/50\n",
      "516/516 [==============================] - 1s 1ms/step - loss: 0.5190\n",
      "Epoch 34/50\n",
      "516/516 [==============================] - 1s 1ms/step - loss: 0.5192\n",
      "Epoch 35/50\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.5190\n",
      "Epoch 36/50\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.5192\n",
      "Epoch 37/50\n",
      "516/516 [==============================] - 1s 1ms/step - loss: 0.5188\n",
      "Epoch 38/50\n",
      "516/516 [==============================] - 1s 1ms/step - loss: 0.5194\n",
      "Epoch 39/50\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.5191\n",
      "Epoch 40/50\n",
      "516/516 [==============================] - 1s 1ms/step - loss: 0.5194\n",
      "Epoch 41/50\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.5190\n",
      "Epoch 42/50\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.5191\n",
      "Epoch 43/50\n",
      "516/516 [==============================] - 1s 1ms/step - loss: 0.5191\n",
      "Epoch 44/50\n",
      "516/516 [==============================] - 1s 1ms/step - loss: 0.5189\n",
      "Epoch 45/50\n",
      "516/516 [==============================] - 1s 1ms/step - loss: 0.5186\n",
      "Epoch 46/50\n",
      "516/516 [==============================] - 1s 1ms/step - loss: 0.5200\n",
      "Epoch 47/50\n",
      "516/516 [==============================] - 1s 1ms/step - loss: 0.5193\n",
      "Epoch 48/50\n",
      "516/516 [==============================] - 1s 1ms/step - loss: 0.5191\n",
      "Epoch 49/50\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.5191\n",
      "Epoch 50/50\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.5186\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x214089605d0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definir el optimizador y la función de pérdida\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mean_squared_error')\n",
    "\n",
    "\n",
    "# Entrenar el modelo\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-Use the trained model to make predictions on the test dataset.\n",
    "\n",
    "-Calculate the mean squared error (MSE) between the predicted and true values.\n",
    "\n",
    "-Print the MSE as a measure of the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129/129 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# Usa el modelo entrenado para hacer predicciones en el conjunto de prueba\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([3.11988   1.398612  1.6972543 ... 7.2466793 2.0868456 1.3117647], shape=(4128,), dtype=float32)\n",
      "MSE:  [3.11988   1.398612  1.6972543 ... 7.2466793 2.0868456 1.3117647]\n"
     ]
    }
   ],
   "source": [
    "# Calcula el error cuadrático medio (MSE) entre los valores predichos y los verdaderos\n",
    "mse = tf.keras.losses.MSE(y_test, y_pred)\n",
    "print(mse)\n",
    "print('MSE: ', mse.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on test data: 2.1642709\n"
     ]
    }
   ],
   "source": [
    "# Calcular el MSE entre las predicciones y las verdaderas etiquetas\n",
    "mse = tf.keras.losses.MSE(y_test, y_pred)\n",
    "print('MSE on test data:', tf.reduce_mean(mse).numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
